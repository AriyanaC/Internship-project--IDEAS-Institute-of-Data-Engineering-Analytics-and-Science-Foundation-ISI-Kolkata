{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "lDJ-pmwxYdkV",
        "RkpC0wRT58k_"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AriyanaC/Internship-project--IDEAS-Institute-of-Data-Engineering-Analytics-and-Science-Foundation-ISI-Kolkata/blob/main/04_fake_news_detection_and_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Project Name: Fake News Detection and Evaluation with Confusion Matrix**\n",
        "####**created by: Suprava Das**"
      ],
      "metadata": {
        "id": "1yvQMZ1cTPbm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement:**\n"
      ],
      "metadata": {
        "id": "d54yPWrsICZS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project addresses the challenge of distinguishing fake news from true news using machine learning techniques. A classification model is trained on textual data, and its effectiveness is evaluated through a confusion matrix to assess accuracy and misclassification patterns."
      ],
      "metadata": {
        "id": "_9cBrQ6oInIy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Introduction:**"
      ],
      "metadata": {
        "id": "se8calhAIy8h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset was compiled from real-world sources; the genuine articles were scraped from Reuters.com (a reputable news website). In contrast, the fake news articles were gathered from various unreliable platforms identified by Politifact (a U.S.-based fact-checking organization) and Wikipedia. The collection covers articles on diverse subjects, though most of them center around politics and world news.\n",
        "\n",
        "The dataset cab also be downloaded from kaggle using the link: www.kaggle.com/datasets/emineyetm/fake-news-detection-datasets"
      ],
      "metadata": {
        "id": "C-cQiBSbI6vB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Packages**"
      ],
      "metadata": {
        "id": "Vr0Ag7NJT4gq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imported all required libraries and installed any missing packages in Google Colab."
      ],
      "metadata": {
        "id": "CN9d_su1N80T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gensim"
      ],
      "metadata": {
        "id": "FxGVjzPUll--",
        "outputId": "8017f77c-57e8-4bff-ea7e-6caf5d21caab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YCYCgAyBi4t",
        "outputId": "80b3faf9-f5e3-48d0-fc72-012ec7b827ce",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# import necessary packages\n",
        "import  matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import re\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from gensim.test.utils import common_texts\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# mounted the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Data Preprocessing**"
      ],
      "metadata": {
        "id": "ba3PZ1ZsTuI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read the csv file using pandas dataframe\n",
        "fake_news_data = pd.read_csv('/content/fake.csv')\n",
        "true_news_data = pd.read_csv('/content/true.csv')"
      ],
      "metadata": {
        "id": "q6XykTJIC-cR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.** View the imported csv file data using Pandas Dataframe."
      ],
      "metadata": {
        "id": "ZzHOTkU0Qg3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(fake_news_data.head())\n",
        "display(true_news_data.head())"
      ],
      "metadata": {
        "id": "y6XdP_nF1qwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake_news_data[\"class\"] = 1  # Fake News data → 1\n",
        "true_news_data[\"class\"] = 0  # True News data → 0"
      ],
      "metadata": {
        "id": "j8UPR_6kDjyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merged true and fake news datasets\n",
        "merged_data = [fake_news_data,true_news_data]\n",
        "df = pd.concat(merged_data,axis=0)"
      ],
      "metadata": {
        "id": "WNaogr4ITRBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2.** drop rows from the dataset consisting null values."
      ],
      "metadata": {
        "id": "Pmt1Dt4WScjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "i2ltWuRMTSsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.** shuffle the data."
      ],
      "metadata": {
        "id": "lwAYZdVGTjF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(frac=1)"
      ],
      "metadata": {
        "id": "tCahSMvTTVYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reset index of the merged dataframe\n",
        "df = df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "ES6BpPEOGtZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view top 10 rows of processed dataset\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "b6NvjxfbGSRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4.** view the text content of a random data point."
      ],
      "metadata": {
        "id": "lnnRk7xMUJUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_row = df.sample(n=1)\n",
        "random_text_content = random_row.iloc[0][\"text\"]\n",
        "print(random_text_content)"
      ],
      "metadata": {
        "id": "QnVr83t9Tqco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Visualization**"
      ],
      "metadata": {
        "id": "ncmn-qORRCxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create a data visualzation of bar/column/line chart of top 5 subjects ->\n",
        "top_5_subjects = (df['subject'].value_counts()).nlargest(5)\n",
        "top_5_subjects.plot(kind='bar', edgecolor='black', stacked=True)\n",
        "plt.xlabel('Subject Name')\n",
        "plt.ylabel('Number of News')"
      ],
      "metadata": {
        "id": "Ji6diJ8MIzdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5.** Create a pie chart to find the percentage of news on different subject."
      ],
      "metadata": {
        "id": "VKGG5NPoVeMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "df['subject'].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=90)\n",
        "plt.title('Percentage of News by Subject')\n",
        "plt.ylabel('')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jpm3uqL3V6r8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Processing**"
      ],
      "metadata": {
        "id": "XpYByiMRzkqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to remove space,special charecter and convert all text into lower case\n",
        "def wordopt(text):\n",
        "  text = text.lower()\n",
        "  text= re.sub(r'https://\\S+|www\\.\\S+','',text) # remove https:// or www.com\n",
        "  text = re.sub(r'[^\\w]',' ', text) #remove special charecter\n",
        "  text= re.sub(r'\\s+',' ',text) #remove multiple space\n",
        "\n",
        "  return text"
      ],
      "metadata": {
        "id": "VTzJE7XygtnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop unnecessary columns for classification purpose\n",
        "df1= df.drop(['title','subject','date'],axis=1)"
      ],
      "metadata": {
        "id": "CxBAn_R2gYtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply wordopt method to the whole dataset and view the text content of a random data point\n",
        "df1['text']=df1['text'].apply(wordopt)\n",
        "df1['text'][100]"
      ],
      "metadata": {
        "id": "tg5lNxJtGksY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building Model**"
      ],
      "metadata": {
        "id": "7zOv17e_5vnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate independent and target columns from the dataset and stored them in x & y variables\n",
        "x= df1['text']\n",
        "y= df1['class']"
      ],
      "metadata": {
        "id": "QndHYbDu50RF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6.** Split the dataset into training and testing sets with 25% test size and store them in x_train, x_test, y_train, and y_test."
      ],
      "metadata": {
        "id": "vdbNrbifWSK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "rKDEsZHE6Ab2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Word Embedding ( Word2Vec )**"
      ],
      "metadata": {
        "id": "3wRqdiRIkqTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import bbc_news data using url link in json format for training Word2Vec word embedding model\n",
        "news = pd.read_json('https://query.data.world/s/7c6p2lxb3wjibfsfbp4mwy7p7y4y2d?dws=00000')\n",
        "news_seg = news['content']\n",
        "print(\"Size of Word Dictonary for training Word2Vec: \",news_seg.shape[0])\n",
        "news_seg.head(2)"
      ],
      "metadata": {
        "id": "SdpOD3v-mLmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply wordopt function for text processing\n",
        "news_seg=news_seg.apply(wordopt)\n",
        "sentences = [sentence.split() for sentence in news_seg ]\n",
        "w2v_model = Word2Vec(sentences,  window=5, min_count=5, workers=4)"
      ],
      "metadata": {
        "id": "AsJm3KoQQqVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to convert a sentence into vector form\n",
        "def vectorize(sentence):\n",
        "    words = sentence.split()\n",
        "    words_vecs = [w2v_model.wv[word] for word in words if word in w2v_model.wv]\n",
        "    if len(words_vecs) == 0:\n",
        "        return np.zeros(100)\n",
        "    words_vecs = np.array(words_vecs)\n",
        "    return words_vecs.mean(axis=0)"
      ],
      "metadata": {
        "id": "lArJrYw97x1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert train and test dataset into vector form\n",
        "xv_train = np.array([vectorize(sentence) for sentence in x_train])\n",
        "xv_test = np.array([vectorize(sentence) for sentence in x_test])"
      ],
      "metadata": {
        "id": "NWzl8y8uldSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Logistic Regression**"
      ],
      "metadata": {
        "id": "VzFibvAbYktA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Trains a Logistic Regression model using vector formed trained data ->\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic_model = LogisticRegression()\n",
        "logistic_model.fit(xv_train,y_train)"
      ],
      "metadata": {
        "id": "DEuVqu0P7KnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# detect the class(fake or true) on test data and evaluates its accuracy on test set\n",
        "y_pred = logistic_model.predict(xv_test)\n",
        "print(\"Prediction on test data: \",y_pred)\n",
        "print(\"Accuracy Score on Test Data: \",logistic_model.score(xv_test,y_test))"
      ],
      "metadata": {
        "id": "uq6D891a7oTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Accuracy Checking**"
      ],
      "metadata": {
        "id": "yJdKrQTFnK1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Precision, Recall, F1 Score of the logistic model ->\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
        "print('Precision:', precision_score(y_test, y_pred))\n",
        "print('Recall:', recall_score(y_test, y_pred))\n",
        "print('F1 score:', f1_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "0VA7sBRdnR-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check overall accuracy using confusion matrix\n",
        "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
        "cm= confusion_matrix(y_test,y_pred)\n",
        "cm_display = ConfusionMatrixDisplay(confusion_matrix = cm)\n",
        "cm_display.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AoxgjMi7Y9HD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Random Forest Classifier**"
      ],
      "metadata": {
        "id": "4mLirHL-J4kT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Model Building and Prediction**"
      ],
      "metadata": {
        "id": "XvJgJX0yYG0M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7.** Use Random Forest Classifer for this classfication purpose and predict the outcomes for test data."
      ],
      "metadata": {
        "id": "OpT7bxd9XfYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#Initialise and train the Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(xv_train,y_train)\n",
        "\n",
        "#Predict on the test data\n",
        "y_pred = rf_model.predict(xv_test)\n",
        "print(\"Prediction on test data using Random Forest:\", y_pred_rf)"
      ],
      "metadata": {
        "id": "pBkqgPskKf6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Accuracy Checking**"
      ],
      "metadata": {
        "id": "fdpRN0MzLJQv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q8.** Find the accuracy, precison, recall, F1 Score of the model while using Random Forest Classsifier and visualize overall accuracy using confusion matrix."
      ],
      "metadata": {
        "id": "lyg4B7b3YX-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check Precision, Recall, F1 score of the Random Forest model\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
        "print('Precision:', precision_score(y_test, y_pred))\n",
        "print('Recall:', recall_score(y_test, y_pred))\n",
        "print('F1 score:', f1_score(y_test, y_pred))\n",
        "\n",
        "#check overall accuracy using confusion matrix\n",
        "cm= confusion_matrix(y_test,y_pred)\n",
        "cm_display = ConfusionMatrixDisplay(confusion_matrix = cm)\n",
        "cm_display.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-saxkm_FKe8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Save the Model using pickle**"
      ],
      "metadata": {
        "id": "L_2hK8LyR1Kj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save the logistic regression model as pickle file\n",
        "import pickle\n",
        "filename1 = '/content/drive/My Drive/IDEAS-TIH/Internship_2025/word2vec_logistic_model.pickle'\n",
        "pickle.dump(logistic_model, open(filename1, 'wb')) #word2vec model"
      ],
      "metadata": {
        "id": "pcmzkeaDGTfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pickle file and checkout model score\n",
        "loaded_model = pickle.load(open(filename1, 'rb'))\n",
        "result = loaded_model.score(xv_test, y_test)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "Y4dOB8p4HMqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q9.** Save the trained Random Forest Model as pickle/svg file in your desired repository for further use."
      ],
      "metadata": {
        "id": "z5L4E0AxZGZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the Random Forest model as a pickle file\n",
        "filename2 = '/content/drive/my Drive/IDEAS-TIH/Internship_2025/word2vec_random_forest_model.pickle'\n",
        "pickle.dump(rf_model, open(filename2, \"wb\"))"
      ],
      "metadata": {
        "id": "jscPGHAdSGMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q10.** Load that saved model in another Notebook. Use it on other dataset for fake news detection."
      ],
      "metadata": {
        "id": "AVG0xCw0ZyvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To mount the Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Defines the wordopt function again for text processing on the new data\n",
        "def wordopt(text):\n",
        "  text = text.lower()\n",
        "  text= re.sub(r'https://\\S+|www\\.\\S+','',text) # removes https:// or www.com\n",
        "  text = re.sub(r'[^\\w]',' ', text) #removes special characters\n",
        "  text= re.sub(r'\\s+',' ',text) #removes multiple spaces\n",
        "  return text\n",
        "\n",
        "# import bbc_news data using url link in json format for training Word2Vec word embedding model\n",
        "news = pd.read_json('https://query.data.world/s/7c6p2lxb3wjibfsfbp4mwy7p7y4y2d?dws=00000')\n",
        "news_seg = news['content']\n",
        "print(\"Size of Word Dictonary for training Word2Vec: \",news_seg.shape[0])\n",
        "news_seg.head(2)\n",
        "\n",
        "# Define the vectorize function again to convert sentences to vectors\n",
        "def vectorize(sentence):\n",
        "    words = sentence.split()\n",
        "    if 'w2v_model' not in globals():\n",
        "        print(\"Word2Vec model not found. Please load or train the model.\")\n",
        "        return np.zeros(100) # Return a zero vector if model is not available\n",
        "\n",
        "    words_vecs = [w2v_model.wv[word] for word in words if word in w2v_model.wv]\n",
        "    if len(words_vecs) == 0:\n",
        "        return np.zeros(100)\n",
        "    words_vecs = np.array(words_vecs)\n",
        "    return words_vecs.mean(axis=0)\n",
        "\n",
        "filename2 = '/content/drive/My Drive/IDEAS-TIH/Internship_2025/word2vec_random_forest_model.pickle'\n",
        "loaded_rf_model = pickle.load(open(filename2, \"rb\"))\n",
        "\n",
        "new_fake_news_data = pd.read_csv('/content/drive/My Drive/IDEAS-TIH/Internship_2025/Fake.csv')\n",
        "\n",
        "# Apply the wordopt function to the new dataset\n",
        "new_fake_news_data['text'] = new_fake_news_data['text'].apply(wordopt)\n",
        "\n",
        "# Convert the text data in the new dataset to vector form using the same vectorize function\n",
        "xv_new_data = np.array([vectorize(sentence) for sentence in new_fake_news_data['text']])\n",
        "\n",
        "# Predict the class (fake or true) on the new data\n",
        "predictions = loaded_rf_model.predict(xv_new_data)\n",
        "\n",
        "# Add the predictions as a new column to your new dataset\n",
        "new_fake_news_data['predicted_class'] = predictions\n",
        "\n",
        "# Display the new dataset with predictions\n",
        "display(new_fake_news_data.head())\n",
        "\n",
        "print(\"Predicted class distribution on new data:\")\n",
        "print(new_fake_news_data['predicted_class'].value_counts())\n"
      ],
      "metadata": {
        "id": "2n52kHs3Ajdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q11(Optional).**\n",
        "\n",
        "\n",
        "1.  Try to enhance the model's accuracy by using adaboost or any other boosting methods.\n",
        "2.  Use TF-IDF or any other vectorizer instead of Word2Vec and study how much it affects on model's accuracy.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2MMFPqDjaffV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "39-EQqKccnJd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}